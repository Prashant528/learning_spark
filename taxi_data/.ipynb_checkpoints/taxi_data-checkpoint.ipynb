{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca98f55f-95dd-49c0-b629-56e2a0eea1a7",
   "metadata": {},
   "source": [
    "Tutorial from: https://www.youtube.com/watch?v=r_Sf6fCB40c&list=PL3MmuxUbc_hJed7dXYoJw8DoCuVHhGEQb&index=54m\n",
    "Spark master UI: http://localhost:4040/jobs/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6678532e-16a3-418e-9863-9b66e95b1737",
   "metadata": {},
   "source": [
    "# Setting up the pyspark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aaf4da88-28af-4b9a-be8d-7af02e73a52f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/11/20 17:07:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd8007ef-080f-4b2e-a5f1-e7373dd42fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.option(\"header\", \"true\")\\\n",
    "    .csv('taxi_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80f1c574-27dc-49d4-be6b-f1fc4fdd8852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(hvfhs_license_num='HV0003', dispatching_base_num='B02682', originating_base_num='B02682', request_datetime='2021-01-01 00:28:09', on_scene_datetime='2021-01-01 00:31:42', pickup_datetime='2021-01-01 00:33:44', dropoff_datetime='2021-01-01 00:49:07', PULocationID='230', DOLocationID='166', trip_miles='5.26', trip_time='923', base_passenger_fare='22.28', tolls='0.0', bcf='0.67', sales_tax='1.98', congestion_surcharge='2.75', airport_fee=None, tips='0.0', driver_pay='14.99', shared_request_flag='N', shared_match_flag='N', access_a_ride_flag=' ', wav_request_flag='N', wav_match_flag='N'),\n",
       " Row(hvfhs_license_num='HV0003', dispatching_base_num='B02682', originating_base_num='B02682', request_datetime='2021-01-01 00:45:56', on_scene_datetime='2021-01-01 00:55:19', pickup_datetime='2021-01-01 00:55:19', dropoff_datetime='2021-01-01 01:18:21', PULocationID='152', DOLocationID='167', trip_miles='3.65', trip_time='1382', base_passenger_fare='18.36', tolls='0.0', bcf='0.55', sales_tax='1.63', congestion_surcharge='0.0', airport_fee=None, tips='0.0', driver_pay='17.06', shared_request_flag='N', shared_match_flag='N', access_a_ride_flag=' ', wav_request_flag='N', wav_match_flag='N'),\n",
       " Row(hvfhs_license_num='HV0003', dispatching_base_num='B02764', originating_base_num='B02764', request_datetime='2021-01-01 00:21:15', on_scene_datetime='2021-01-01 00:22:41', pickup_datetime='2021-01-01 00:23:56', dropoff_datetime='2021-01-01 00:38:05', PULocationID='233', DOLocationID='142', trip_miles='3.51', trip_time='849', base_passenger_fare='14.05', tolls='0.0', bcf='0.48', sales_tax='1.25', congestion_surcharge='2.75', airport_fee=None, tips='0.94', driver_pay='12.98', shared_request_flag='N', shared_match_flag='N', access_a_ride_flag=' ', wav_request_flag='N', wav_match_flag='N'),\n",
       " Row(hvfhs_license_num='HV0003', dispatching_base_num='B02764', originating_base_num='B02764', request_datetime='2021-01-01 00:39:12', on_scene_datetime='2021-01-01 00:42:37', pickup_datetime='2021-01-01 00:42:51', dropoff_datetime='2021-01-01 00:45:50', PULocationID='142', DOLocationID='143', trip_miles='0.74', trip_time='179', base_passenger_fare='7.91', tolls='0.0', bcf='0.24', sales_tax='0.7', congestion_surcharge='2.75', airport_fee=None, tips='0.0', driver_pay='7.41', shared_request_flag='N', shared_match_flag='N', access_a_ride_flag=' ', wav_request_flag='N', wav_match_flag='N'),\n",
       " Row(hvfhs_license_num='HV0003', dispatching_base_num='B02764', originating_base_num='B02764', request_datetime='2021-01-01 00:46:11', on_scene_datetime='2021-01-01 00:47:17', pickup_datetime='2021-01-01 00:48:14', dropoff_datetime='2021-01-01 01:08:42', PULocationID='143', DOLocationID='78', trip_miles='9.2', trip_time='1228', base_passenger_fare='27.11', tolls='0.0', bcf='0.81', sales_tax='2.41', congestion_surcharge='2.75', airport_fee=None, tips='0.0', driver_pay='22.44', shared_request_flag='N', shared_match_flag='N', access_a_ride_flag=' ', wav_request_flag='N', wav_match_flag='N')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d72959-42de-4063-89e4-3684c4e4be38",
   "metadata": {},
   "source": [
    "# How to read data and assign suitable datatypes?\n",
    "### Defining the schema for spark dataframe \n",
    "### Since all of the data is currently in string format, we want to determine the exact datatypes too."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42aa8055-d92f-4517-9910-cd472d949f76",
   "metadata": {},
   "source": [
    "## Using pandas to determine the data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ffb9f47b-92ce-403a-ae96-c4222ba70431",
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n 1000 taxi_data.csv > head.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d769c20a-fcbc-431a-b05e-f110d5fe2ff5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hvfhs_license_num        object\n",
       "dispatching_base_num     object\n",
       "originating_base_num     object\n",
       "request_datetime         object\n",
       "on_scene_datetime        object\n",
       "pickup_datetime          object\n",
       "dropoff_datetime         object\n",
       "PULocationID              int64\n",
       "DOLocationID              int64\n",
       "trip_miles              float64\n",
       "trip_time                 int64\n",
       "base_passenger_fare     float64\n",
       "tolls                   float64\n",
       "bcf                     float64\n",
       "sales_tax               float64\n",
       "congestion_surcharge    float64\n",
       "airport_fee             float64\n",
       "tips                    float64\n",
       "driver_pay              float64\n",
       "shared_request_flag      object\n",
       "shared_match_flag        object\n",
       "access_a_ride_flag       object\n",
       "wav_request_flag         object\n",
       "wav_match_flag           object\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_pandas = pd.read_csv('head.csv')\n",
    "df_pandas.dtypes"
   ]
  },
  {
   "cell_type": "raw",
   "id": "444acdf1-18fa-4537-946e-643417e833a9",
   "metadata": {},
   "source": [
    "#### All data was in string format. It could identify numbers and floats but some are just 'objects'.\n",
    "#### Let's see how spark reads the same datatypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0255f2c-e21d-4f7b-b9a4-a92ddabc337a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('hvfhs_license_num', StringType(), True), StructField('dispatching_base_num', StringType(), True), StructField('originating_base_num', StringType(), True), StructField('request_datetime', StringType(), True), StructField('on_scene_datetime', StringType(), True), StructField('pickup_datetime', StringType(), True), StructField('dropoff_datetime', StringType(), True), StructField('PULocationID', LongType(), True), StructField('DOLocationID', LongType(), True), StructField('trip_miles', DoubleType(), True), StructField('trip_time', LongType(), True), StructField('base_passenger_fare', DoubleType(), True), StructField('tolls', DoubleType(), True), StructField('bcf', DoubleType(), True), StructField('sales_tax', DoubleType(), True), StructField('congestion_surcharge', DoubleType(), True), StructField('airport_fee', DoubleType(), True), StructField('tips', DoubleType(), True), StructField('driver_pay', DoubleType(), True), StructField('shared_request_flag', StringType(), True), StructField('shared_match_flag', StringType(), True), StructField('access_a_ride_flag', StringType(), True), StructField('wav_request_flag', StringType(), True), StructField('wav_match_flag', StringType(), True)])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Converting pandas dataframe to spark data frame\n",
    "spark.createDataFrame(df_pandas).schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781b667d-85d8-4883-8d88-b948aaa1b7be",
   "metadata": {},
   "source": [
    "It can find almost all datatypes except some date time data types. We could also downsize some types (e.g. double, longType) to save memory. Let's modify the some of the above data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5482cc4-27bf-49b2-a19c-0028dcf8d048",
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking in the current schema and modifying the datatypes of the fields as needed. e.g. pickup_datetime was string but I need it as date time.\n",
    "from pyspark.sql import types\n",
    "schema = types.StructType([\n",
    "    types.StructField('hvfhs_license_num', types.StringType(), True), \n",
    "    types.StructField('dispatching_base_num', types.StringType(), True), \n",
    "    types.StructField('originating_base_num', types.StringType(), True), \n",
    "    types.StructField('request_datetime', types.StringType(), True), \n",
    "    types.StructField('on_scene_datetime', types.StringType(), True), \n",
    "    types.StructField('pickup_datetime', types.TimestampType(), True), \n",
    "    types.StructField('dropoff_datetime', types.TimestampType(), True), \n",
    "    types.StructField('PULocationID', types.IntegerType(), True), \n",
    "    types.StructField('DOLocationID', types.IntegerType(), True), \n",
    "    types.StructField('trip_miles', types.DoubleType(), True), \n",
    "    types.StructField('trip_time', types.IntegerType(), True), \n",
    "    types.StructField('base_passenger_fare', types.DoubleType(), True), \n",
    "    types.StructField('tolls', types.DoubleType(), True), \n",
    "    types.StructField('bcf', types.DoubleType(), True), \n",
    "    types.StructField('sales_tax', types.DoubleType(), True), \n",
    "    types.StructField('congestion_surcharge', types.DoubleType(), True), \n",
    "    types.StructField('airport_fee', types.DoubleType(), True), \n",
    "    types.StructField('tips', types.DoubleType(), True), \n",
    "    types.StructField('driver_pay', types.DoubleType(), True), \n",
    "    types.StructField('shared_request_flag', types.StringType(), True), \n",
    "    types.StructField('shared_match_flag', types.StringType(), True),\n",
    "    types.StructField('access_a_ride_flag', types.StringType(), True), \n",
    "    types.StructField('wav_request_flag', types.StringType(), True), \n",
    "    types.StructField('wav_match_flag', types.StringType(), True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2e9f737-9539-45de-b342-30352503853a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the same data with the new schema\n",
    "df = spark.read.option(\"header\", \"true\")\\\n",
    "    .schema(schema)\\\n",
    "    .csv('taxi_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83b9a28c-9d82-4df2-ba0d-580707648ffa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(hvfhs_license_num='HV0003', dispatching_base_num='B02682', originating_base_num='B02682', request_datetime='2021-01-01 00:28:09', on_scene_datetime='2021-01-01 00:31:42', pickup_datetime=datetime.datetime(2021, 1, 1, 0, 33, 44), dropoff_datetime=datetime.datetime(2021, 1, 1, 0, 49, 7), PULocationID=230, DOLocationID=166, trip_miles=5.26, trip_time=923, base_passenger_fare=22.28, tolls=0.0, bcf=0.67, sales_tax=1.98, congestion_surcharge=2.75, airport_fee=None, tips=0.0, driver_pay=14.99, shared_request_flag='N', shared_match_flag='N', access_a_ride_flag=' ', wav_request_flag='N', wav_match_flag='N'),\n",
       " Row(hvfhs_license_num='HV0003', dispatching_base_num='B02682', originating_base_num='B02682', request_datetime='2021-01-01 00:45:56', on_scene_datetime='2021-01-01 00:55:19', pickup_datetime=datetime.datetime(2021, 1, 1, 0, 55, 19), dropoff_datetime=datetime.datetime(2021, 1, 1, 1, 18, 21), PULocationID=152, DOLocationID=167, trip_miles=3.65, trip_time=1382, base_passenger_fare=18.36, tolls=0.0, bcf=0.55, sales_tax=1.63, congestion_surcharge=0.0, airport_fee=None, tips=0.0, driver_pay=17.06, shared_request_flag='N', shared_match_flag='N', access_a_ride_flag=' ', wav_request_flag='N', wav_match_flag='N'),\n",
       " Row(hvfhs_license_num='HV0003', dispatching_base_num='B02764', originating_base_num='B02764', request_datetime='2021-01-01 00:21:15', on_scene_datetime='2021-01-01 00:22:41', pickup_datetime=datetime.datetime(2021, 1, 1, 0, 23, 56), dropoff_datetime=datetime.datetime(2021, 1, 1, 0, 38, 5), PULocationID=233, DOLocationID=142, trip_miles=3.51, trip_time=849, base_passenger_fare=14.05, tolls=0.0, bcf=0.48, sales_tax=1.25, congestion_surcharge=2.75, airport_fee=None, tips=0.94, driver_pay=12.98, shared_request_flag='N', shared_match_flag='N', access_a_ride_flag=' ', wav_request_flag='N', wav_match_flag='N'),\n",
       " Row(hvfhs_license_num='HV0003', dispatching_base_num='B02764', originating_base_num='B02764', request_datetime='2021-01-01 00:39:12', on_scene_datetime='2021-01-01 00:42:37', pickup_datetime=datetime.datetime(2021, 1, 1, 0, 42, 51), dropoff_datetime=datetime.datetime(2021, 1, 1, 0, 45, 50), PULocationID=142, DOLocationID=143, trip_miles=0.74, trip_time=179, base_passenger_fare=7.91, tolls=0.0, bcf=0.24, sales_tax=0.7, congestion_surcharge=2.75, airport_fee=None, tips=0.0, driver_pay=7.41, shared_request_flag='N', shared_match_flag='N', access_a_ride_flag=' ', wav_request_flag='N', wav_match_flag='N'),\n",
       " Row(hvfhs_license_num='HV0003', dispatching_base_num='B02764', originating_base_num='B02764', request_datetime='2021-01-01 00:46:11', on_scene_datetime='2021-01-01 00:47:17', pickup_datetime=datetime.datetime(2021, 1, 1, 0, 48, 14), dropoff_datetime=datetime.datetime(2021, 1, 1, 1, 8, 42), PULocationID=143, DOLocationID=78, trip_miles=9.2, trip_time=1228, base_passenger_fare=27.11, tolls=0.0, bcf=0.81, sales_tax=2.41, congestion_surcharge=2.75, airport_fee=None, tips=0.0, driver_pay=22.44, shared_request_flag='N', shared_match_flag='N', access_a_ride_flag=' ', wav_request_flag='N', wav_match_flag='N'),\n",
       " Row(hvfhs_license_num='HV0005', dispatching_base_num='B02510', originating_base_num=None, request_datetime='2021-01-01 00:04:00', on_scene_datetime=None, pickup_datetime=datetime.datetime(2021, 1, 1, 0, 6, 59), dropoff_datetime=datetime.datetime(2021, 1, 1, 0, 43, 1), PULocationID=88, DOLocationID=42, trip_miles=9.725, trip_time=2162, base_passenger_fare=28.11, tolls=0.0, bcf=0.84, sales_tax=2.49, congestion_surcharge=2.75, airport_fee=None, tips=0.0, driver_pay=28.9, shared_request_flag='N', shared_match_flag='N', access_a_ride_flag='N', wav_request_flag='N', wav_match_flag='N'),\n",
       " Row(hvfhs_license_num='HV0005', dispatching_base_num='B02510', originating_base_num=None, request_datetime='2021-01-01 00:40:06', on_scene_datetime=None, pickup_datetime=datetime.datetime(2021, 1, 1, 0, 50), dropoff_datetime=datetime.datetime(2021, 1, 1, 1, 4, 57), PULocationID=42, DOLocationID=151, trip_miles=2.469, trip_time=897, base_passenger_fare=25.03, tolls=0.0, bcf=0.75, sales_tax=2.22, congestion_surcharge=0.0, airport_fee=None, tips=0.0, driver_pay=15.01, shared_request_flag='N', shared_match_flag='N', access_a_ride_flag='N', wav_request_flag='N', wav_match_flag='N'),\n",
       " Row(hvfhs_license_num='HV0003', dispatching_base_num='B02764', originating_base_num='B02764', request_datetime='2021-01-01 00:10:36', on_scene_datetime='2021-01-01 00:12:28', pickup_datetime=datetime.datetime(2021, 1, 1, 0, 14, 30), dropoff_datetime=datetime.datetime(2021, 1, 1, 0, 50, 27), PULocationID=71, DOLocationID=226, trip_miles=13.53, trip_time=2157, base_passenger_fare=29.67, tolls=0.0, bcf=1.04, sales_tax=3.08, congestion_surcharge=0.0, airport_fee=None, tips=0.0, driver_pay=34.2, shared_request_flag='N', shared_match_flag='N', access_a_ride_flag=' ', wav_request_flag='N', wav_match_flag='N'),\n",
       " Row(hvfhs_license_num='HV0003', dispatching_base_num='B02875', originating_base_num='B02875', request_datetime='2021-01-01 00:21:17', on_scene_datetime='2021-01-01 00:22:25', pickup_datetime=datetime.datetime(2021, 1, 1, 0, 22, 54), dropoff_datetime=datetime.datetime(2021, 1, 1, 0, 30, 20), PULocationID=112, DOLocationID=255, trip_miles=1.6, trip_time=446, base_passenger_fare=6.89, tolls=0.0, bcf=0.21, sales_tax=0.61, congestion_surcharge=0.0, airport_fee=None, tips=0.0, driver_pay=6.26, shared_request_flag='N', shared_match_flag='N', access_a_ride_flag=' ', wav_request_flag='N', wav_match_flag='N'),\n",
       " Row(hvfhs_license_num='HV0003', dispatching_base_num='B02875', originating_base_num='B02875', request_datetime='2021-01-01 00:36:57', on_scene_datetime='2021-01-01 00:38:09', pickup_datetime=datetime.datetime(2021, 1, 1, 0, 40, 12), dropoff_datetime=datetime.datetime(2021, 1, 1, 0, 53, 31), PULocationID=255, DOLocationID=232, trip_miles=3.2, trip_time=800, base_passenger_fare=11.51, tolls=0.0, bcf=0.53, sales_tax=1.03, congestion_surcharge=2.75, airport_fee=None, tips=2.82, driver_pay=10.99, shared_request_flag='N', shared_match_flag='N', access_a_ride_flag=' ', wav_request_flag='N', wav_match_flag='N')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's check the data\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d198b2f1-7426-416e-b416-497e2c0729a2",
   "metadata": {},
   "source": [
    "### In the result, we can see that the data is parsed as integers and date time objects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228d43bf-7046-4c30-a589-34ef102b81cd",
   "metadata": {},
   "source": [
    "## Partitioning the data\n",
    "In real scenarios, we want to make use of as much spark clusters as possible. So, we want to have the big csv file partitioned into many small chunks so that each cluster can pick up one chunk and work on that parallely. \n",
    "Partitioning the data in spark is lazy mode i.e. it will partition the data whenever the data is needed somewhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b023ac21-ccf8-42d6-a9a1-37ea9b00fbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.repartition(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8c531db-961c-417e-93cf-b25880e70567",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/20 19:03:31 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "24/11/20 19:03:31 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 84.44% for 9 writers\n",
      "24/11/20 19:03:31 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 76.00% for 10 writers\n",
      "24/11/20 19:03:31 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 69.09% for 11 writers\n",
      "24/11/20 19:03:37 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 76.00% for 10 writers\n",
      "24/11/20 19:03:37 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 84.44% for 9 writers\n",
      "24/11/20 19:03:37 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "24/11/20 19:03:37 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "24/11/20 19:03:37 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 84.44% for 9 writers\n",
      "24/11/20 19:03:37 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 76.00% for 10 writers\n",
      "24/11/20 19:03:37 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 69.09% for 11 writers\n",
      "24/11/20 19:03:40 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 76.00% for 10 writers\n",
      "24/11/20 19:03:40 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 69.09% for 11 writers\n",
      "24/11/20 19:03:40 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 76.00% for 10 writers\n",
      "24/11/20 19:03:40 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 84.44% for 9 writers\n",
      "24/11/20 19:03:40 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Writing the partitioned data into parquet files\n",
    "df.write.parquet('fhvhv/2021/01/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "970c4b41-e0fd-461b-b299-3d4fb3b6d6c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      25\n"
     ]
    }
   ],
   "source": [
    "# We can see the parquet files inside the directory: fhvhv/2021/01/\n",
    "! ls fhvhv/2021/01/ | wc -l\n",
    "# One extra file is a _SUCCESS file which denotes that the partitioning has been done successfully. Maybe it can be used as a trgger for other jobs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "myvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
