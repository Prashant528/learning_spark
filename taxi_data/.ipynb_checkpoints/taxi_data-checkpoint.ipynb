{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca98f55f-95dd-49c0-b629-56e2a0eea1a7",
   "metadata": {},
   "source": [
    "Tutorial from: https://www.youtube.com/watch?v=r_Sf6fCB40c&list=PL3MmuxUbc_hJed7dXYoJw8DoCuVHhGEQb&index=54m\n",
    "Spark master UI: http://localhost:4040/jobs/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6678532e-16a3-418e-9863-9b66e95b1737",
   "metadata": {},
   "source": [
    "# Setting up the pyspark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aaf4da88-28af-4b9a-be8d-7af02e73a52f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/28 10:05:52 WARN Utils: Your hostname, Prashants-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.254.38 instead (on interface en0)\n",
      "24/11/28 10:05:52 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/11/28 10:05:52 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd8007ef-080f-4b2e-a5f1-e7373dd42fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.option(\"header\", \"true\")\\\n",
    "    .csv('data/taxi_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80f1c574-27dc-49d4-be6b-f1fc4fdd8852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(hvfhs_license_num='HV0003', dispatching_base_num='B02682', originating_base_num='B02682', request_datetime='2021-01-01 00:28:09', on_scene_datetime='2021-01-01 00:31:42', pickup_datetime='2021-01-01 00:33:44', dropoff_datetime='2021-01-01 00:49:07', PULocationID='230', DOLocationID='166', trip_miles='5.26', trip_time='923', base_passenger_fare='22.28', tolls='0.0', bcf='0.67', sales_tax='1.98', congestion_surcharge='2.75', airport_fee=None, tips='0.0', driver_pay='14.99', shared_request_flag='N', shared_match_flag='N', access_a_ride_flag=' ', wav_request_flag='N', wav_match_flag='N'),\n",
       " Row(hvfhs_license_num='HV0003', dispatching_base_num='B02682', originating_base_num='B02682', request_datetime='2021-01-01 00:45:56', on_scene_datetime='2021-01-01 00:55:19', pickup_datetime='2021-01-01 00:55:19', dropoff_datetime='2021-01-01 01:18:21', PULocationID='152', DOLocationID='167', trip_miles='3.65', trip_time='1382', base_passenger_fare='18.36', tolls='0.0', bcf='0.55', sales_tax='1.63', congestion_surcharge='0.0', airport_fee=None, tips='0.0', driver_pay='17.06', shared_request_flag='N', shared_match_flag='N', access_a_ride_flag=' ', wav_request_flag='N', wav_match_flag='N'),\n",
       " Row(hvfhs_license_num='HV0003', dispatching_base_num='B02764', originating_base_num='B02764', request_datetime='2021-01-01 00:21:15', on_scene_datetime='2021-01-01 00:22:41', pickup_datetime='2021-01-01 00:23:56', dropoff_datetime='2021-01-01 00:38:05', PULocationID='233', DOLocationID='142', trip_miles='3.51', trip_time='849', base_passenger_fare='14.05', tolls='0.0', bcf='0.48', sales_tax='1.25', congestion_surcharge='2.75', airport_fee=None, tips='0.94', driver_pay='12.98', shared_request_flag='N', shared_match_flag='N', access_a_ride_flag=' ', wav_request_flag='N', wav_match_flag='N'),\n",
       " Row(hvfhs_license_num='HV0003', dispatching_base_num='B02764', originating_base_num='B02764', request_datetime='2021-01-01 00:39:12', on_scene_datetime='2021-01-01 00:42:37', pickup_datetime='2021-01-01 00:42:51', dropoff_datetime='2021-01-01 00:45:50', PULocationID='142', DOLocationID='143', trip_miles='0.74', trip_time='179', base_passenger_fare='7.91', tolls='0.0', bcf='0.24', sales_tax='0.7', congestion_surcharge='2.75', airport_fee=None, tips='0.0', driver_pay='7.41', shared_request_flag='N', shared_match_flag='N', access_a_ride_flag=' ', wav_request_flag='N', wav_match_flag='N'),\n",
       " Row(hvfhs_license_num='HV0003', dispatching_base_num='B02764', originating_base_num='B02764', request_datetime='2021-01-01 00:46:11', on_scene_datetime='2021-01-01 00:47:17', pickup_datetime='2021-01-01 00:48:14', dropoff_datetime='2021-01-01 01:08:42', PULocationID='143', DOLocationID='78', trip_miles='9.2', trip_time='1228', base_passenger_fare='27.11', tolls='0.0', bcf='0.81', sales_tax='2.41', congestion_surcharge='2.75', airport_fee=None, tips='0.0', driver_pay='22.44', shared_request_flag='N', shared_match_flag='N', access_a_ride_flag=' ', wav_request_flag='N', wav_match_flag='N')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d72959-42de-4063-89e4-3684c4e4be38",
   "metadata": {},
   "source": [
    "# How to read data and assign suitable datatypes?\n",
    "### Defining the schema for spark dataframe \n",
    "### Since all of the data is currently in string format, we want to determine the exact datatypes too."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42aa8055-d92f-4517-9910-cd472d949f76",
   "metadata": {},
   "source": [
    "## Using pandas to determine the data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffb9f47b-92ce-403a-ae96-c4222ba70431",
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n 1000 data/taxi_data.csv > head.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d769c20a-fcbc-431a-b05e-f110d5fe2ff5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hvfhs_license_num        object\n",
       "dispatching_base_num     object\n",
       "originating_base_num     object\n",
       "request_datetime         object\n",
       "on_scene_datetime        object\n",
       "pickup_datetime          object\n",
       "dropoff_datetime         object\n",
       "PULocationID              int64\n",
       "DOLocationID              int64\n",
       "trip_miles              float64\n",
       "trip_time                 int64\n",
       "base_passenger_fare     float64\n",
       "tolls                   float64\n",
       "bcf                     float64\n",
       "sales_tax               float64\n",
       "congestion_surcharge    float64\n",
       "airport_fee             float64\n",
       "tips                    float64\n",
       "driver_pay              float64\n",
       "shared_request_flag      object\n",
       "shared_match_flag        object\n",
       "access_a_ride_flag       object\n",
       "wav_request_flag         object\n",
       "wav_match_flag           object\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_pandas = pd.read_csv('head.csv')\n",
    "df_pandas.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333278f7-2114-47de-9b02-3ca8c091c665",
   "metadata": {},
   "source": [
    "#### All data was in string format. It could identify numbers and floats but some are just 'objects'.\n",
    "#### Let's see how spark reads the same datatypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0255f2c-e21d-4f7b-b9a4-a92ddabc337a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('hvfhs_license_num', StringType(), True), StructField('dispatching_base_num', StringType(), True), StructField('originating_base_num', StringType(), True), StructField('request_datetime', StringType(), True), StructField('on_scene_datetime', StringType(), True), StructField('pickup_datetime', StringType(), True), StructField('dropoff_datetime', StringType(), True), StructField('PULocationID', LongType(), True), StructField('DOLocationID', LongType(), True), StructField('trip_miles', DoubleType(), True), StructField('trip_time', LongType(), True), StructField('base_passenger_fare', DoubleType(), True), StructField('tolls', DoubleType(), True), StructField('bcf', DoubleType(), True), StructField('sales_tax', DoubleType(), True), StructField('congestion_surcharge', DoubleType(), True), StructField('airport_fee', DoubleType(), True), StructField('tips', DoubleType(), True), StructField('driver_pay', DoubleType(), True), StructField('shared_request_flag', StringType(), True), StructField('shared_match_flag', StringType(), True), StructField('access_a_ride_flag', StringType(), True), StructField('wav_request_flag', StringType(), True), StructField('wav_match_flag', StringType(), True)])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Converting pandas dataframe to spark data frame\n",
    "spark.createDataFrame(df_pandas).schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781b667d-85d8-4883-8d88-b948aaa1b7be",
   "metadata": {},
   "source": [
    "It can find almost all datatypes except some date time data types. We could also downsize some types (e.g. double, longType) to save memory. Let's modify the some of the above data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5482cc4-27bf-49b2-a19c-0028dcf8d048",
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking in the current schema and modifying the datatypes of the fields as needed. e.g. pickup_datetime was string but I need it as date time.\n",
    "from pyspark.sql import types\n",
    "schema = types.StructType([\n",
    "    types.StructField('hvfhs_license_num', types.StringType(), True), \n",
    "    types.StructField('dispatching_base_num', types.StringType(), True), \n",
    "    types.StructField('originating_base_num', types.StringType(), True), \n",
    "    types.StructField('request_datetime', types.StringType(), True), \n",
    "    types.StructField('on_scene_datetime', types.StringType(), True), \n",
    "    types.StructField('pickup_datetime', types.TimestampType(), True), \n",
    "    types.StructField('dropoff_datetime', types.TimestampType(), True), \n",
    "    types.StructField('PULocationID', types.IntegerType(), True), \n",
    "    types.StructField('DOLocationID', types.IntegerType(), True), \n",
    "    types.StructField('trip_miles', types.DoubleType(), True), \n",
    "    types.StructField('trip_time', types.IntegerType(), True), \n",
    "    types.StructField('base_passenger_fare', types.DoubleType(), True), \n",
    "    types.StructField('tolls', types.DoubleType(), True), \n",
    "    types.StructField('bcf', types.DoubleType(), True), \n",
    "    types.StructField('sales_tax', types.DoubleType(), True), \n",
    "    types.StructField('congestion_surcharge', types.DoubleType(), True), \n",
    "    types.StructField('airport_fee', types.DoubleType(), True), \n",
    "    types.StructField('tips', types.DoubleType(), True), \n",
    "    types.StructField('driver_pay', types.DoubleType(), True), \n",
    "    types.StructField('shared_request_flag', types.StringType(), True), \n",
    "    types.StructField('shared_match_flag', types.StringType(), True),\n",
    "    types.StructField('access_a_ride_flag', types.StringType(), True), \n",
    "    types.StructField('wav_request_flag', types.StringType(), True), \n",
    "    types.StructField('wav_match_flag', types.StringType(), True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2e9f737-9539-45de-b342-30352503853a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the same data with the new schema\n",
    "df = spark.read.option(\"header\", \"true\")\\\n",
    "    .schema(schema)\\\n",
    "    .csv('data/taxi_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83b9a28c-9d82-4df2-ba0d-580707648ffa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(hvfhs_license_num='HV0003', dispatching_base_num='B02682', originating_base_num='B02682', request_datetime='2021-01-01 00:28:09', on_scene_datetime='2021-01-01 00:31:42', pickup_datetime=datetime.datetime(2021, 1, 1, 0, 33, 44), dropoff_datetime=datetime.datetime(2021, 1, 1, 0, 49, 7), PULocationID=230, DOLocationID=166, trip_miles=5.26, trip_time=923, base_passenger_fare=22.28, tolls=0.0, bcf=0.67, sales_tax=1.98, congestion_surcharge=2.75, airport_fee=None, tips=0.0, driver_pay=14.99, shared_request_flag='N', shared_match_flag='N', access_a_ride_flag=' ', wav_request_flag='N', wav_match_flag='N'),\n",
       " Row(hvfhs_license_num='HV0003', dispatching_base_num='B02682', originating_base_num='B02682', request_datetime='2021-01-01 00:45:56', on_scene_datetime='2021-01-01 00:55:19', pickup_datetime=datetime.datetime(2021, 1, 1, 0, 55, 19), dropoff_datetime=datetime.datetime(2021, 1, 1, 1, 18, 21), PULocationID=152, DOLocationID=167, trip_miles=3.65, trip_time=1382, base_passenger_fare=18.36, tolls=0.0, bcf=0.55, sales_tax=1.63, congestion_surcharge=0.0, airport_fee=None, tips=0.0, driver_pay=17.06, shared_request_flag='N', shared_match_flag='N', access_a_ride_flag=' ', wav_request_flag='N', wav_match_flag='N'),\n",
       " Row(hvfhs_license_num='HV0003', dispatching_base_num='B02764', originating_base_num='B02764', request_datetime='2021-01-01 00:21:15', on_scene_datetime='2021-01-01 00:22:41', pickup_datetime=datetime.datetime(2021, 1, 1, 0, 23, 56), dropoff_datetime=datetime.datetime(2021, 1, 1, 0, 38, 5), PULocationID=233, DOLocationID=142, trip_miles=3.51, trip_time=849, base_passenger_fare=14.05, tolls=0.0, bcf=0.48, sales_tax=1.25, congestion_surcharge=2.75, airport_fee=None, tips=0.94, driver_pay=12.98, shared_request_flag='N', shared_match_flag='N', access_a_ride_flag=' ', wav_request_flag='N', wav_match_flag='N'),\n",
       " Row(hvfhs_license_num='HV0003', dispatching_base_num='B02764', originating_base_num='B02764', request_datetime='2021-01-01 00:39:12', on_scene_datetime='2021-01-01 00:42:37', pickup_datetime=datetime.datetime(2021, 1, 1, 0, 42, 51), dropoff_datetime=datetime.datetime(2021, 1, 1, 0, 45, 50), PULocationID=142, DOLocationID=143, trip_miles=0.74, trip_time=179, base_passenger_fare=7.91, tolls=0.0, bcf=0.24, sales_tax=0.7, congestion_surcharge=2.75, airport_fee=None, tips=0.0, driver_pay=7.41, shared_request_flag='N', shared_match_flag='N', access_a_ride_flag=' ', wav_request_flag='N', wav_match_flag='N'),\n",
       " Row(hvfhs_license_num='HV0003', dispatching_base_num='B02764', originating_base_num='B02764', request_datetime='2021-01-01 00:46:11', on_scene_datetime='2021-01-01 00:47:17', pickup_datetime=datetime.datetime(2021, 1, 1, 0, 48, 14), dropoff_datetime=datetime.datetime(2021, 1, 1, 1, 8, 42), PULocationID=143, DOLocationID=78, trip_miles=9.2, trip_time=1228, base_passenger_fare=27.11, tolls=0.0, bcf=0.81, sales_tax=2.41, congestion_surcharge=2.75, airport_fee=None, tips=0.0, driver_pay=22.44, shared_request_flag='N', shared_match_flag='N', access_a_ride_flag=' ', wav_request_flag='N', wav_match_flag='N'),\n",
       " Row(hvfhs_license_num='HV0005', dispatching_base_num='B02510', originating_base_num=None, request_datetime='2021-01-01 00:04:00', on_scene_datetime=None, pickup_datetime=datetime.datetime(2021, 1, 1, 0, 6, 59), dropoff_datetime=datetime.datetime(2021, 1, 1, 0, 43, 1), PULocationID=88, DOLocationID=42, trip_miles=9.725, trip_time=2162, base_passenger_fare=28.11, tolls=0.0, bcf=0.84, sales_tax=2.49, congestion_surcharge=2.75, airport_fee=None, tips=0.0, driver_pay=28.9, shared_request_flag='N', shared_match_flag='N', access_a_ride_flag='N', wav_request_flag='N', wav_match_flag='N'),\n",
       " Row(hvfhs_license_num='HV0005', dispatching_base_num='B02510', originating_base_num=None, request_datetime='2021-01-01 00:40:06', on_scene_datetime=None, pickup_datetime=datetime.datetime(2021, 1, 1, 0, 50), dropoff_datetime=datetime.datetime(2021, 1, 1, 1, 4, 57), PULocationID=42, DOLocationID=151, trip_miles=2.469, trip_time=897, base_passenger_fare=25.03, tolls=0.0, bcf=0.75, sales_tax=2.22, congestion_surcharge=0.0, airport_fee=None, tips=0.0, driver_pay=15.01, shared_request_flag='N', shared_match_flag='N', access_a_ride_flag='N', wav_request_flag='N', wav_match_flag='N'),\n",
       " Row(hvfhs_license_num='HV0003', dispatching_base_num='B02764', originating_base_num='B02764', request_datetime='2021-01-01 00:10:36', on_scene_datetime='2021-01-01 00:12:28', pickup_datetime=datetime.datetime(2021, 1, 1, 0, 14, 30), dropoff_datetime=datetime.datetime(2021, 1, 1, 0, 50, 27), PULocationID=71, DOLocationID=226, trip_miles=13.53, trip_time=2157, base_passenger_fare=29.67, tolls=0.0, bcf=1.04, sales_tax=3.08, congestion_surcharge=0.0, airport_fee=None, tips=0.0, driver_pay=34.2, shared_request_flag='N', shared_match_flag='N', access_a_ride_flag=' ', wav_request_flag='N', wav_match_flag='N'),\n",
       " Row(hvfhs_license_num='HV0003', dispatching_base_num='B02875', originating_base_num='B02875', request_datetime='2021-01-01 00:21:17', on_scene_datetime='2021-01-01 00:22:25', pickup_datetime=datetime.datetime(2021, 1, 1, 0, 22, 54), dropoff_datetime=datetime.datetime(2021, 1, 1, 0, 30, 20), PULocationID=112, DOLocationID=255, trip_miles=1.6, trip_time=446, base_passenger_fare=6.89, tolls=0.0, bcf=0.21, sales_tax=0.61, congestion_surcharge=0.0, airport_fee=None, tips=0.0, driver_pay=6.26, shared_request_flag='N', shared_match_flag='N', access_a_ride_flag=' ', wav_request_flag='N', wav_match_flag='N'),\n",
       " Row(hvfhs_license_num='HV0003', dispatching_base_num='B02875', originating_base_num='B02875', request_datetime='2021-01-01 00:36:57', on_scene_datetime='2021-01-01 00:38:09', pickup_datetime=datetime.datetime(2021, 1, 1, 0, 40, 12), dropoff_datetime=datetime.datetime(2021, 1, 1, 0, 53, 31), PULocationID=255, DOLocationID=232, trip_miles=3.2, trip_time=800, base_passenger_fare=11.51, tolls=0.0, bcf=0.53, sales_tax=1.03, congestion_surcharge=2.75, airport_fee=None, tips=2.82, driver_pay=10.99, shared_request_flag='N', shared_match_flag='N', access_a_ride_flag=' ', wav_request_flag='N', wav_match_flag='N')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's check the data\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d198b2f1-7426-416e-b416-497e2c0729a2",
   "metadata": {},
   "source": [
    "### In the result, we can see that the data is parsed as integers and date time objects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228d43bf-7046-4c30-a589-34ef102b81cd",
   "metadata": {},
   "source": [
    "## Partitioning the data\n",
    "In real scenarios, we want to make use of as much spark clusters as possible. So, we want to have the big csv file partitioned into many small chunks so that each cluster can pick up one chunk and work on that parallely. \n",
    "Partitioning the data in spark is lazy mode i.e. it will partition the data whenever the data is needed somewhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b023ac21-ccf8-42d6-a9a1-37ea9b00fbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random choice for 24.\n",
    "df = df.repartition(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c531db-961c-417e-93cf-b25880e70567",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Writing the partitioned data into parquet files\n",
    "df.write.parquet('data/fhvhv/2021/01/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "970c4b41-e0fd-461b-b299-3d4fb3b6d6c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      25\n"
     ]
    }
   ],
   "source": [
    "# We can see the parquet files inside the directory: fhvhv/2021/01/\n",
    "! ls data/fhvhv/2021/01/ | wc -l\n",
    "# One extra file is a _SUCCESS file which denotes that the partitioning has been done successfully. Maybe it can be used as a trgger for other jobs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8c9d67-840a-43b4-ba02-6268abd2a6b4",
   "metadata": {},
   "source": [
    "### Reading the parquet files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "961440b1-1327-4916-8f86-87118b844e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- hvfhs_license_num: string (nullable = true)\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- originating_base_num: string (nullable = true)\n",
      " |-- request_datetime: string (nullable = true)\n",
      " |-- on_scene_datetime: string (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropoff_datetime: timestamp (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- trip_miles: double (nullable = true)\n",
      " |-- trip_time: integer (nullable = true)\n",
      " |-- base_passenger_fare: double (nullable = true)\n",
      " |-- tolls: double (nullable = true)\n",
      " |-- bcf: double (nullable = true)\n",
      " |-- sales_tax: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      " |-- airport_fee: double (nullable = true)\n",
      " |-- tips: double (nullable = true)\n",
      " |-- driver_pay: double (nullable = true)\n",
      " |-- shared_request_flag: string (nullable = true)\n",
      " |-- shared_match_flag: string (nullable = true)\n",
      " |-- access_a_ride_flag: string (nullable = true)\n",
      " |-- wav_request_flag: string (nullable = true)\n",
      " |-- wav_match_flag: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet('data/fhvhv/2021/01/')\n",
    "df.printSchema()\n",
    "# Notice how the schema is preserved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f349321c-7d48-4361-9fa1-c53ea502723e",
   "metadata": {},
   "source": [
    "### Selecting columns and filtering by column values\n",
    "If I did just df.select('pickup_datetime', 'dropoff_datetime').filter(df.hvfhs_license_num== 'HV0003'), spark would not run it right away (as seen in the Spark MasterUI) because it is executed lazily. But when I do .show() it has to run the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6bc2bcec-baee-4786-b34e-2bf768a1f9eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+\n",
      "|    pickup_datetime|   dropoff_datetime|\n",
      "+-------------------+-------------------+\n",
      "|2021-01-02 18:51:52|2021-01-02 18:58:05|\n",
      "|2021-01-02 17:54:29|2021-01-02 18:02:27|\n",
      "|2021-01-02 14:44:27|2021-01-02 14:57:26|\n",
      "|2021-01-02 15:28:32|2021-01-02 15:34:13|\n",
      "|2021-01-01 18:07:11|2021-01-01 18:17:54|\n",
      "|2021-01-01 05:50:20|2021-01-01 06:01:20|\n",
      "|2021-01-01 09:48:42|2021-01-01 09:51:57|\n",
      "|2021-01-02 14:37:08|2021-01-02 14:59:03|\n",
      "|2021-01-01 17:15:42|2021-01-01 17:20:41|\n",
      "|2021-01-02 20:22:08|2021-01-02 20:36:46|\n",
      "|2021-01-01 21:55:19|2021-01-01 22:05:38|\n",
      "|2021-01-02 10:39:57|2021-01-02 10:44:59|\n",
      "|2021-01-01 10:43:01|2021-01-01 11:25:26|\n",
      "|2021-01-01 00:40:58|2021-01-01 00:50:46|\n",
      "|2021-01-02 12:37:19|2021-01-02 12:39:25|\n",
      "|2021-01-02 15:34:47|2021-01-02 15:45:25|\n",
      "|2021-01-02 02:31:36|2021-01-02 02:46:22|\n",
      "|2021-01-02 12:37:12|2021-01-02 12:43:30|\n",
      "|2021-01-01 17:39:10|2021-01-01 17:52:40|\n",
      "|2021-01-03 04:25:50|2021-01-03 04:34:46|\n",
      "+-------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('pickup_datetime', 'dropoff_datetime').filter(df.hvfhs_license_num== 'HV0003').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24007163-5a95-468e-998e-13eae4a28038",
   "metadata": {},
   "source": [
    "### There are two types of commands in spark: Transformations and Actions.\n",
    "- Transformations: Select, filtering, joins, groups etc. Lazily executed.\n",
    "- Actions: Show, take(head), write etc. Eagerly executed (along with all previous transformations.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d936ee-bbae-44eb-8865-a0b26dee207a",
   "metadata": {},
   "source": [
    "### We can use functions like in SQL. e.g. to_date(), max(), sum(). They are in pyspark.sql."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "29600d7e-71ef-412c-affe-bedf0d0eccea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "97cf9593-71ff-4350-895f-d24d50550c52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------+\n",
      "|pickup_date|dropoff_date|\n",
      "+-----------+------------+\n",
      "| 2021-01-02|  2021-01-02|\n",
      "| 2021-01-02|  2021-01-02|\n",
      "| 2021-01-02|  2021-01-02|\n",
      "| 2021-01-01|  2021-01-01|\n",
      "| 2021-01-02|  2021-01-02|\n",
      "| 2021-01-01|  2021-01-01|\n",
      "| 2021-01-01|  2021-01-01|\n",
      "| 2021-01-01|  2021-01-01|\n",
      "| 2021-01-02|  2021-01-02|\n",
      "| 2021-01-01|  2021-01-01|\n",
      "| 2021-01-02|  2021-01-02|\n",
      "| 2021-01-02|  2021-01-02|\n",
      "| 2021-01-01|  2021-01-01|\n",
      "| 2021-01-02|  2021-01-02|\n",
      "| 2021-01-01|  2021-01-01|\n",
      "| 2021-01-01|  2021-01-01|\n",
      "| 2021-01-01|  2021-01-01|\n",
      "| 2021-01-01|  2021-01-01|\n",
      "| 2021-01-03|  2021-01-03|\n",
      "| 2021-01-02|  2021-01-02|\n",
      "+-----------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's change the datetime to dates\n",
    "df\\\n",
    ".withColumn('pickup_date', F.to_date(df.pickup_datetime))\\\n",
    ".withColumn('dropoff_date', F.to_date(df.dropoff_datetime))\\\n",
    ".select('pickup_date', 'dropoff_date') \\\n",
    ".show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e72b12-69ea-4071-8b3e-8581bfb6013b",
   "metadata": {},
   "source": [
    "#### What if we need some extra functions than provided? (Difference from SQL)\n",
    "##### We can use user defined functions(udf) as transformations for the data. Some could be quite difficult to implement with SQL but here we can just use python functions and make them udfs. This makes Spark more powerful.\n",
    "- For example: The business needs to convert dispatching_base_num(e.g.B02764) to integer by removing 'B' and check if the number is divisible by 2(Put result_yes afterwards) or not(result_no afterwards)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e8cfac8a-b16f-4844-b84c-b9480e1ba08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_base_num(base_num):\n",
    "    num = int(base_num[1:])\n",
    "    if num%2==0:\n",
    "        new_num = str(num/2) + '_yes'\n",
    "    else:\n",
    "        new_num  = str(num/2) + '_no'\n",
    "    return new_num\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d7fdd4e9-9753-4003-9d48-406c58ecd6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1382.0_yes\n",
      "1382.5_no\n"
     ]
    }
   ],
   "source": [
    "# testing the function\n",
    "print(transform_base_num('B02764'))\n",
    "print(transform_base_num('B02765'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "72e97971-9609-4b59-a44b-610bd4d7f2fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+\n",
      "|dispatching_base_num|modified_base_num|\n",
      "+--------------------+-----------------+\n",
      "|              B02875|        1437.5_no|\n",
      "|              B02836|       1418.0_yes|\n",
      "|              B02876|       1438.0_yes|\n",
      "|              B02510|       1255.0_yes|\n",
      "|              B02764|       1382.0_yes|\n",
      "|              B02866|       1433.0_yes|\n",
      "|              B02866|       1433.0_yes|\n",
      "|              B02888|       1444.0_yes|\n",
      "|              B02764|       1382.0_yes|\n",
      "|              B02870|       1435.0_yes|\n",
      "|              B02510|       1255.0_yes|\n",
      "|              B02883|        1441.5_no|\n",
      "|              B02884|       1442.0_yes|\n",
      "|              B02869|        1434.5_no|\n",
      "|              B02764|       1382.0_yes|\n",
      "|              B02764|       1382.0_yes|\n",
      "|              B02510|       1255.0_yes|\n",
      "|              B02510|       1255.0_yes|\n",
      "|              B02800|       1400.0_yes|\n",
      "|              B02510|       1255.0_yes|\n",
      "+--------------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#defining udf for the function\n",
    "transform_base_num_udf = F.udf(transform_base_num, returnType=types.StringType())\n",
    "#using the udf\n",
    "df\\\n",
    ".withColumn('modified_base_num', transform_base_num_udf(df.dispatching_base_num))\\\n",
    ".select('dispatching_base_num', 'modified_base_num') \\\n",
    ".show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "myvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
